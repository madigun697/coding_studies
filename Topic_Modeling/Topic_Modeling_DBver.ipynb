{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./colab_results/reuters/lda_result.pkl', 'rb') as f:\n",
    "    lda_results = pickle.load(f)\n",
    "f.close()    \n",
    "    \n",
    "document_topic_counts, topic_word_counts, topic_counts, document_lengths, distinct_words = lda_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./colab_results/reuters/kmeans_result.pkl', 'rb') as f:\n",
    "    km_results = pickle.load(f)\n",
    "f.close()    \n",
    "    \n",
    "km_model = km_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./colab_results/reuters/dec_result.pkl', 'rb') as f:\n",
    "    dec_results = pickle.load(f)\n",
    "f.close()    \n",
    "    \n",
    "dec_model = dec_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_csv('./colab_results/reuters/reuter21578.tsv', sep='\\t', usecols=['text', 'new_topic'])\n",
    "processed_docs = pd.read_csv('./colab_results/reuters/preprocessed_docs.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents.reset_index()\n",
    "documents.columns = ['id', 'document', 'new_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>new_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Showers continued throughout the week in the B...</td>\n",
       "      <td>Commodity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The U.S. Agriculture Department reported the f...</td>\n",
       "      <td>Commodity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Argentine grain board figures show crop regist...</td>\n",
       "      <td>Commodity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Champion Products Inc said its board of direct...</td>\n",
       "      <td>Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Computer Terminal Systems Inc said it has comp...</td>\n",
       "      <td>Corporate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           document  new_topic\n",
       "0   0  Showers continued throughout the week in the B...  Commodity\n",
       "1   1  The U.S. Agriculture Department reported the f...  Commodity\n",
       "2   2  Argentine grain board figures show crop regist...  Commodity\n",
       "3   3  Champion Products Inc said its board of direct...  Corporate\n",
       "4   4  Computer Terminal Systems Inc said it has comp...  Corporate"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['shower', 'continu', 'week', 'bahia', 'cocoa'...\n",
       "1    ['agricultur', 'depart', 'report', 'farmer', '...\n",
       "2    ['argentin', 'grain', 'board', 'figur', 'crop'...\n",
       "3    ['champion', 'product', 'say', 'board', 'direc...\n",
       "4    ['termin', 'system', 'say', 'complet', 'sale',...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_map = dict.fromkeys(documents.new_topic.unique().tolist(), 0)\n",
    "\n",
    "for i, k in enumerate(topic_map):\n",
    "    topic_map[k] = i\n",
    "    \n",
    "label_result = np.array(documents.new_topic.apply(lambda x: topic_map[x]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Commodity': 2,\n",
       " 'Corporate': 1,\n",
       " 'Currency': 4,\n",
       " 'Economic': 3,\n",
       " 'Energy': 0,\n",
       " 'Subject': 5}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model['documents'] = documents\n",
    "saved_model['processed_docs'] = processed_docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* postprocess for lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_dists = np.array([topic_word_counts[i][k] for i in range(6) for k in list(distinct_words)]).reshape((6, len(distinct_words))) \n",
    "doc_topic_dists = pd.DataFrame([d.values() for d in document_topic_counts]).fillna(0).values\n",
    "doc_topic_dists = normalize(doc_topic_dists, norm='l1')\n",
    "doc_lengths = np.array(document_lengths)\n",
    "vocab = list(distinct_words)\n",
    "term_frequency = np.array([topic_word_counts[i][k] for i in range(6) for k in list(distinct_words)]).reshape((6, len(distinct_words))).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model['lda_result'] = {\n",
    "        'document_topic_counts':document_topic_counts,\n",
    "        'topic_word_counts':topic_word_counts,\n",
    "        'topic_counts':topic_counts,\n",
    "        'document_lengths':document_lengths,\n",
    "        'distinct_words':distinct_words\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model['kmeans_result'] = {\n",
    "        'cluster_centers' : km_model.cluster_centers_,\n",
    "        'labels' : label_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model['kmeans_result'] = km_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model['dec_result'] = dec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.99899776e-19, -3.38813179e-20,  1.15196481e-19, ...,\n",
       "        -1.18584613e-20,  4.57397792e-20,  4.65868121e-21],\n",
       "       [ 1.62630326e-19,  5.84452734e-20,  1.25360876e-19, ...,\n",
       "        -1.22819777e-20,  1.93123512e-19, -4.06575815e-20],\n",
       "       [ 5.03544441e-05,  1.10724429e-05,  1.43995601e-19, ...,\n",
       "         5.92498422e-06,  3.23660231e-05,  6.67493409e-06],\n",
       "       [-9.82558219e-20, -2.28698896e-20,  9.99498878e-20, ...,\n",
       "        -1.05879118e-20, -1.15196481e-19,  8.89384595e-21],\n",
       "       [-3.04931861e-20, -1.01643954e-20,  1.20278679e-19, ...,\n",
       "        -1.18584613e-20,  1.15196481e-19, -1.65171425e-20],\n",
       "       [-8.60585474e-19,  2.48180654e-19,  4.67074692e-05, ...,\n",
       "         1.66865491e-19, -5.81064602e-19, -1.07573184e-19]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['documents', 'processed_docs', 'lda_result', 'dec_result', 'kmeans_result'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[documents] <class 'pandas.core.frame.DataFrame'>\n",
      "[processed_docs] <class 'pandas.core.series.Series'>\n",
      "[lda_result] <class 'dict'>: dict_keys(['document_topic_counts', 'document_lengths', 'topic_counts', 'distinct_words', 'topic_word_counts'])([<class 'list'>, <class 'list'>, <class 'list'>, <class 'set'>, <class 'list'>])\n",
      "[dec_result] <class 'numpy.ndarray'>\n",
      "[kmeans_result] <class 'dict'>: dict_keys(['labels', 'cluster_centers'])([<class 'numpy.ndarray'>, <class 'numpy.ndarray'>])\n"
     ]
    }
   ],
   "source": [
    "for k in saved_model.keys():\n",
    "    if type(saved_model[k]) == dict:\n",
    "        print(\"[%s] <class 'dict'>: %s(%s)\" % (k, str(saved_model[k].keys()), [type(saved_model[k][t]) for t in saved_model[k].keys()]))\n",
    "    else:\n",
    "        print(\"[%s] %s\" % (k, type(saved_model[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./colab_results/reuters/saved_model_reuters_no_km_with_label.pkl', 'wb') as f:\n",
    "    pickle.dump(saved_model, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(saved_model['kmeans_result']) == sklearn.cluster.k_means_.KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as genldavis\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = saved_model['documents']\n",
    "processed_docs = saved_model['processed_docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = processed_docs.apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "tsne_data = vect.fit_transform([' '.join(d) for d in processed_docs]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_result = saved_model['kmeans_result']\n",
    "if type(kmeans_result) == sklearn.cluster.k_means_.KMeans:\n",
    "    kmeans_centers = kmeans_result.cluster_centers_\n",
    "    kmeans_labels = kmeans_result.labels_\n",
    "else:\n",
    "    kmeans_centers = kmeans_result['cluster_centers']\n",
    "    kmeans_labels = kmeans_result['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normalize(tsne_data, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10377, 17217)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17217"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(np.sum(processed_docs.values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracelee/.pyenv/versions/for_jupyter/lib/python3.5/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator KMeans from version 0.19.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('./drug_tables.pkl', 'rb') as f:\n",
    "    drug_tables = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracelee/.pyenv/versions/for_jupyter/lib/python3.5/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator KMeans from version 0.20.1 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('./km_gracee_result.pkl', 'rb') as f:\n",
    "    km_results = pickle.load(f)\n",
    "f.close()    \n",
    "    \n",
    "km_model = km_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_tables['kmeans_result'] = km_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8178)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./grace_drug_table.pkl', 'wb') as f:\n",
    "    pickle.dump(drug_tables, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/\n",
    "* http://replet.tistory.com/67 (그냥 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap-learn\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/ce/33e260133f2a8e6c24a434e22de31f1dff01d58b3beec033d5c1b544bfb7/umap-learn-0.3.7.tar.gz (40kB)\n",
      "\u001b[K    100% |████████████████████████████████| 40kB 566kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from umap-learn)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from umap-learn)\n",
      "Requirement already satisfied: scipy>=0.19 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from umap-learn)\n",
      "Collecting numba>=0.37 (from umap-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/79/25/03ea2db69dfa3e2b42607afa106b54e29858f9921da9299abf447c484414/numba-0.41.0-cp35-cp35m-macosx_10_9_x86_64.whl (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 450kB/s \n",
      "\u001b[?25hCollecting llvmlite>=0.26.0dev0 (from numba>=0.37->umap-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/a5/b8d25cbdfd94b5647f6107bb39802ce67afc098cc9cd9935f40415ff4def/llvmlite-0.26.0-cp35-cp35m-macosx_10_9_x86_64.whl (12.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.5MB 59kB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: umap-learn\n",
      "  Running setup.py bdist_wheel for umap-learn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/gracelee/Library/Caches/pip/wheels/be/a5/95/6cb125db66c98d790fa627977d6cacd16c59a6bfeeab957aa3\n",
      "Successfully built umap-learn\n",
      "Installing collected packages: llvmlite, numba, umap-learn\n",
      "Successfully installed llvmlite-0.26.0 numba-0.41.0 umap-learn-0.3.7\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 51s, sys: 6.86 s, total: 3min 58s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "%time umap_data = umap.UMAP().fit_transform(tsne_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.title('Decomposition using UMAP')\n",
    "\n",
    "umap_df = pd.concat([pd.DataFrame(umap_data, columns=['pc1', 'pc2', 'pc3']), pd.DataFrame(dec_model, columns=['label'])], axis=1)\n",
    "\n",
    "for l in umap_df.label.unique():\n",
    "    clusterPoints = umap_df[umap_df.label == l]\n",
    "    ax.scatter(clusterPoints.pc1, clusterPoints.pc2, clusterPoints.pc3)\n",
    "    \n",
    "ax.legend(umap_df.label.unique())    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim as genldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genldavis.prepare()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
