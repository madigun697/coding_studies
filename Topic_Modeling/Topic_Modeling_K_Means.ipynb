{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TsKdaZaYb6S"
   },
   "source": [
    "# Topic Modeling using K-Means\n",
    "\n",
    "### References\n",
    "\n",
    "* Data: ABC News Headlines (https://www.kaggle.com/therohk/million-headlines/version/6)\n",
    "* Preprocess: https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "* K-Means: https://lovit.github.io/nlp/2018/09/27/pyldavis_kmeans/#topic=0&lambda=1&term="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBHXrVXj9rsK"
   },
   "source": [
    "### Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ut-GgvMmTiG6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 999)\n",
    "news_data = pd.read_csv('./mallet_top_sen.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1239,
     "status": "ok",
     "timestamp": 1541566038639,
     "user": {
      "displayName": "유주형",
      "photoUrl": "https://lh5.googleusercontent.com/-fg1dF67RQts/AAAAAAAAAAI/AAAAAAAAeAQ/W4wNdGVPToE/s64/photo.jpg",
      "userId": "03494144523560780027"
     },
     "user_tz": -540
    },
    "id": "B6iJDggyXxMH",
    "outputId": "5391d2f4-6a96-4566-c58e-925f7375d47a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contribu</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Origin_Text</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>44029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2935</td>\n",
       "      <td>analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart</td>\n",
       "      <td>Hazard Ratio  (and 95% Confidence Intervals)  in Univariate and Multivariate Analysis of Predictors of Major Cardiac Events  (Cardiac Death or Worsening of Heart Failure Leading to Heart Transplantation)</td>\n",
       "      <td>['hazard', 'ratio', 'confid', 'interv', 'univari', 'multivari', 'analysi', 'predictor', 'major', 'cardiac', 'event', 'cardiac', 'death', 'worsen', 'heart', 'failur', 'lead', 'heart', 'transplant']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart</td>\n",
       "      <td>Left Ventricular and Right Ventricular Ejection Fractions, Left Ventricular and Right Ventricular Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations for Both Ventricles in 30 Cases of Left Sided WPW legend</td>\n",
       "      <td>['leav', 'ventricular', 'right', 'ventricular', 'eject', 'fraction', 'leav', 'ventricular', 'right', 'ventricular', 'mean', 'phase', 'leav', 'right', 'mean', 'phase', 'differ', 'rmp', 'phase', 'standard', 'deviat', 'ventricl', 'case', 'leav', 'side', 'wpw']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2817</td>\n",
       "      <td>analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart</td>\n",
       "      <td>Partial Regression Coefficients  (All Subjects, n = 262)  for Forward Stepwise Linear Regression for Dependent Variables Augmentation Pressure and Augmentation Index    legend</td>\n",
       "      <td>['partial', 'regress', 'coeffici', 'subject', 'forward', 'stepwis', 'linear', 'regress', 'depend', 'variabl', 'augment', 'pressur', 'augment', 'index']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2797</td>\n",
       "      <td>analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart</td>\n",
       "      <td>Left Ventricular  (LVEF)  and Right Ventricular  (RVEF)  Ejection Fractions, Left Ventricular  (LVMP)  and Right Ventricular  (RVMP)  Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations  (LVPSD and RVPSD)  for Both Ventricles in 14 Cases of Right Sided WPW legend</td>\n",
       "      <td>['leav', 'ventricular', 'lvef', 'right', 'ventricular', 'rvef', 'eject', 'fraction', 'leav', 'ventricular', 'lvmp', 'right', 'ventricular', 'rvmp', 'mean', 'phase', 'leav', 'right', 'mean', 'phase', 'differ', 'rmp', 'phase', 'standard', 'deviat', 'lvpsd', 'rvpsd', 'ventricl', 'case', 'right', 'side', 'wpw']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2782</td>\n",
       "      <td>analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart</td>\n",
       "      <td>Predictors of Mortality by Multivariable Analysis: Variables Are Shown in the Order They Entered a Stepwise Cox Regression Model</td>\n",
       "      <td>['predictor', 'mortal', 'multivari', 'analysi', 'variabl', 'show', 'order', 'enter', 'stepwis', 'cox', 'regress', 'model']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id  Topic_Num  Topic_Perc_Contribu  \\\n",
       "0           0  44029        0.0               0.2935   \n",
       "1           1  23344        0.0               0.2836   \n",
       "2           2  41163        0.0               0.2817   \n",
       "3           3  23343        0.0               0.2797   \n",
       "4           4  24968        0.0               0.2782   \n",
       "\n",
       "                                                                          Topic_Keywords  \\\n",
       "0  analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart   \n",
       "1  analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart   \n",
       "2  analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart   \n",
       "3  analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart   \n",
       "4  analysi, multivari, regress, variabl, model, predictor, cardiac, time, univari, heart   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    Origin_Text  \\\n",
       "0                                                                                                   Hazard Ratio  (and 95% Confidence Intervals)  in Univariate and Multivariate Analysis of Predictors of Major Cardiac Events  (Cardiac Death or Worsening of Heart Failure Leading to Heart Transplantation)   \n",
       "1                                                           Left Ventricular and Right Ventricular Ejection Fractions, Left Ventricular and Right Ventricular Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations for Both Ventricles in 30 Cases of Left Sided WPW legend   \n",
       "2                                                                                                                               Partial Regression Coefficients  (All Subjects, n = 262)  for Forward Stepwise Linear Regression for Dependent Variables Augmentation Pressure and Augmentation Index    legend   \n",
       "3  Left Ventricular  (LVEF)  and Right Ventricular  (RVEF)  Ejection Fractions, Left Ventricular  (LVMP)  and Right Ventricular  (RVMP)  Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations  (LVPSD and RVPSD)  for Both Ventricles in 14 Cases of Right Sided WPW legend   \n",
       "4                                                                                                                                                                              Predictors of Mortality by Multivariable Analysis: Variables Are Shown in the Order They Entered a Stepwise Cox Regression Model   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                   Text  \n",
       "0                                                                                                                  ['hazard', 'ratio', 'confid', 'interv', 'univari', 'multivari', 'analysi', 'predictor', 'major', 'cardiac', 'event', 'cardiac', 'death', 'worsen', 'heart', 'failur', 'lead', 'heart', 'transplant']  \n",
       "1                                                     ['leav', 'ventricular', 'right', 'ventricular', 'eject', 'fraction', 'leav', 'ventricular', 'right', 'ventricular', 'mean', 'phase', 'leav', 'right', 'mean', 'phase', 'differ', 'rmp', 'phase', 'standard', 'deviat', 'ventricl', 'case', 'leav', 'side', 'wpw']  \n",
       "2                                                                                                                                                               ['partial', 'regress', 'coeffici', 'subject', 'forward', 'stepwis', 'linear', 'regress', 'depend', 'variabl', 'augment', 'pressur', 'augment', 'index']  \n",
       "3  ['leav', 'ventricular', 'lvef', 'right', 'ventricular', 'rvef', 'eject', 'fraction', 'leav', 'ventricular', 'lvmp', 'right', 'ventricular', 'rvmp', 'mean', 'phase', 'leav', 'right', 'mean', 'phase', 'differ', 'rmp', 'phase', 'standard', 'deviat', 'lvpsd', 'rvpsd', 'ventricl', 'case', 'right', 'side', 'wpw']  \n",
       "4                                                                                                                                                                                            ['predictor', 'mortal', 'multivari', 'analysi', 'variabl', 'show', 'order', 'enter', 'stepwis', 'cox', 'regress', 'model']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePl8Ln9b_8NV"
   },
   "source": [
    "#### Extract target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1541566040044,
     "user": {
      "displayName": "유주형",
      "photoUrl": "https://lh5.googleusercontent.com/-fg1dF67RQts/AAAAAAAAAAI/AAAAAAAAeAQ/W4wNdGVPToE/s64/photo.jpg",
      "userId": "03494144523560780027"
     },
     "user_tz": -540
    },
    "id": "aFIUgkTfZ2Jl",
    "outputId": "a537fb6a-b4a6-4a96-be3e-c4676af07360"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracelee/.pyenv/versions/for_jupyter/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin_Text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hazard Ratio  (and 95% Confidence Intervals)  in Univariate and Multivariate Analysis of Predictors of Major Cardiac Events  (Cardiac Death or Worsening of Heart Failure Leading to Heart Transplantation)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Left Ventricular and Right Ventricular Ejection Fractions, Left Ventricular and Right Ventricular Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations for Both Ventricles in 30 Cases of Left Sided WPW legend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Partial Regression Coefficients  (All Subjects, n = 262)  for Forward Stepwise Linear Regression for Dependent Variables Augmentation Pressure and Augmentation Index    legend</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Left Ventricular  (LVEF)  and Right Ventricular  (RVEF)  Ejection Fractions, Left Ventricular  (LVMP)  and Right Ventricular  (RVMP)  Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations  (LVPSD and RVPSD)  for Both Ventricles in 14 Cases of Right Sided WPW legend</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Predictors of Mortality by Multivariable Analysis: Variables Are Shown in the Order They Entered a Stepwise Cox Regression Model</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                    Origin_Text  \\\n",
       "0                                                                                                   Hazard Ratio  (and 95% Confidence Intervals)  in Univariate and Multivariate Analysis of Predictors of Major Cardiac Events  (Cardiac Death or Worsening of Heart Failure Leading to Heart Transplantation)   \n",
       "1                                                           Left Ventricular and Right Ventricular Ejection Fractions, Left Ventricular and Right Ventricular Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations for Both Ventricles in 30 Cases of Left Sided WPW legend   \n",
       "2                                                                                                                               Partial Regression Coefficients  (All Subjects, n = 262)  for Forward Stepwise Linear Regression for Dependent Variables Augmentation Pressure and Augmentation Index    legend   \n",
       "3  Left Ventricular  (LVEF)  and Right Ventricular  (RVEF)  Ejection Fractions, Left Ventricular  (LVMP)  and Right Ventricular  (RVMP)  Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations  (LVPSD and RVPSD)  for Both Ventricles in 14 Cases of Right Sided WPW legend   \n",
       "4                                                                                                                                                                              Predictors of Mortality by Multivariable Analysis: Variables Are Shown in the Order They Entered a Stepwise Cox Regression Model   \n",
       "\n",
       "   index  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      3  \n",
       "4      4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text = news_data[['Origin_Text']]\n",
    "data_text['index'] = news_data[['Unnamed: 0']]\n",
    "documents = data_text\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_GA1U3fAECz"
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "* Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from gensim)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from gensim)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from gensim)\n",
      "Requirement already satisfied: boto3 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: bz2file in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: requests in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: boto>=2.32 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.45 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: docutils>=0.10 in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from botocore<1.13.0,>=1.12.45->boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from botocore<1.13.0,>=1.12.45->boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages\n",
      "Requirement already satisfied: six in /Users/gracelee/.pyenv/versions/3.5.4/envs/for_jupyter/lib/python3.5/site-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1541566041043,
     "user": {
      "displayName": "유주형",
      "photoUrl": "https://lh5.googleusercontent.com/-fg1dF67RQts/AAAAAAAAAAI/AAAAAAAAeAQ/W4wNdGVPToE/s64/photo.jpg",
      "userId": "03494144523560780027"
     },
     "user_tz": -540
    },
    "id": "EuX1F67TYXFc",
    "outputId": "c2c74f56-a6fb-466b-bb63-28a117cb62d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracelee/.pyenv/versions/for_jupyter/lib/python3.5/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gracelee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LO8jzrS7AIrp"
   },
   "source": [
    "* Preprocess\n",
    " 1. simple_preprocess: Split Text by whitespace\n",
    " 2. STOPWORDS: Remove stopwords\n",
    " 3. lemmatize_stemming\n",
    " \n",
    "* lemmatize_stemming\n",
    " - Lemmatizing & Stemming Replace word with original form\n",
    " - Lemmatizing consider whether the word exist in the real world\n",
    " - pos means a position of the word\n",
    " - https://m.blog.naver.com/PostView.nhn?blogId=vangarang&logNo=220963244354&proxyReferer=https%3A%2F%2Fwww.google.com%2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1V0FdvKJZezi"
   },
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xJK8DKBJvSq"
   },
   "source": [
    "* Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1541566043352,
     "user": {
      "displayName": "유주형",
      "photoUrl": "https://lh5.googleusercontent.com/-fg1dF67RQts/AAAAAAAAAAI/AAAAAAAAeAQ/W4wNdGVPToE/s64/photo.jpg",
      "userId": "03494144523560780027"
     },
     "user_tz": -540
    },
    "id": "AkEpG_ey86-3",
    "outputId": "f4f392d1-d5b0-436e-db0b-2fee33d68ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Treatment', 'efficacy', 'at', 'week', '36', 'for', 'the', 'modified', 'intention-to-treat', 'population', 'in', 'the', 'open-label', 'period', 'and', 'at', 'week', '88', 'for', 'the', 'modified', 'intention-to-treat', 'subpopulations', 'in', 'the', 'double-blind', 'period']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['treatment', 'efficaci', 'week', 'modifi', 'intent', 'treat', 'popul', 'open', 'label', 'period', 'week', 'modifi', 'intent', 'treat', 'subpopul', 'doubl', 'blind', 'period']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 100].values[0][0]\n",
    "print('original document: ')\n",
    "\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "go6me5u-TzlG"
   },
   "source": [
    "* Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164587,
     "status": "ok",
     "timestamp": 1541566208089,
     "user": {
      "displayName": "유주형",
      "photoUrl": "https://lh5.googleusercontent.com/-fg1dF67RQts/AAAAAAAAAAI/AAAAAAAAeAQ/W4wNdGVPToE/s64/photo.jpg",
      "userId": "03494144523560780027"
     },
     "user_tz": -540
    },
    "id": "EGbICJX5aIMg",
    "outputId": "f32a035a-c555-4056-86ea-c971f2e07337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 613 ms, sys: 2.88 ms, total: 616 ms\n",
      "Wall time: 620 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                                                        [hazard, ratio, confid, interv, univari, multivari, analysi, predictor, major, cardiac, event, cardiac, death, worsen, heart, failur, lead, heart, transplant]\n",
       "1                                           [leav, ventricular, right, ventricular, eject, fraction, leav, ventricular, right, ventricular, mean, phase, leav, right, mean, phase, differ, phase, standard, deviat, ventricl, case, leav, side, legend]\n",
       "2                                                                                                                   [partial, regress, coeffici, subject, forward, stepwis, linear, regress, depend, variabl, augment, pressur, augment, index, legend]\n",
       "3    [leav, ventricular, lvef, right, ventricular, rvef, eject, fraction, leav, ventricular, lvmp, right, ventricular, rvmp, mean, phase, leav, right, mean, phase, differ, phase, standard, deviat, lvpsd, rvpsd, ventricl, case, right, side, legend]\n",
       "4                                                                                                                                                         [predictor, mortal, multivari, analysi, variabl, show, order, enter, stepwis, regress, model]\n",
       "5                                                                [logist, regress, model, post, transplant, predictor, normal, leav, ventricular, eject, fraction, lvef, post, transplant, period, refer, group, group, lvef, post, transplant, period]\n",
       "6                                                                                                        [result, surviv, analysi, proport, hazard, model, combin, point, cardiac, mortal, urgent, heart, transplant, readmiss, congest, heart, failur]\n",
       "7                                                                                                    [impact, normal, versus, reduc, leav, ventricular, eject, fraction, mortal, congest, heart, failur, case, result, proport, hazard, regress, model]\n",
       "8                                                                                               [descript, leav, ventricular, eject, fraction, lvef, differ, time, period, time, transplant, evalu, wait, list, transplant, follow, kidney, transplant]\n",
       "9                                                                                                                                                              [univari, regress, analysi, proport, hazard, analysi, predictor, cardiac, death, legend]\n",
       "Name: Origin_Text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time processed_docs = documents['Origin_Text'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://datascienceschool.net/view-notebook/3e7aadbf88ed4f0d87a76f9ddc925d69/\n",
    "* https://lumiamitie.github.io/r/python/tsne-for-r-py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TSNE모델에는 transform 메소드가 없고 fit_transform만 있음\n",
    "# library import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents['Origin_Text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.1 ms, sys: 1.96 ms, total: 40.1 ms\n",
      "Wall time: 39.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "%time vect.fit(documents['Origin_Text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 ms, sys: 5.96 ms, total: 37.4 ms\n",
      "Wall time: 37.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time tsne_data = vect.transform(documents['Origin_Text'].values.tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 957 ms, total: 17.4 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%time tsne_result = TSNE(learning_rate=300, init='pca').fit_transform(np.array(tsne_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.5887737,  15.092761 ],\n",
       "       [-26.751963 ,  -1.2962534],\n",
       "       [ -7.7378716,   5.3128357],\n",
       "       [-26.751284 ,  -1.296099 ],\n",
       "       [ -5.5161123,   9.251663 ],\n",
       "       [ -0.8104641,  16.026785 ],\n",
       "       [ -4.9360843,  10.798    ],\n",
       "       [ -7.008701 ,  11.168139 ],\n",
       "       [-10.108216 ,   8.083006 ],\n",
       "       [ -5.114168 ,  13.3855915]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(documents.Origin_Text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "# L2 normalizing\n",
    "X = normalize(X, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=8, init=\"random\", max_iter=3000).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained labels and cluster centers\n",
    "labels = kmeans_model.labels_\n",
    "centers = kmeans_model.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means 결과를 LDAvis로 시각화\n",
    "* https://lovit.github.io/nlp/2018/09/27/pyldavis_kmeans/#topic=0&lambda=1&term="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* topic_term_dists\n",
    "* doc_topic_dists\n",
    "* doc_lengths\n",
    "* vocab\n",
    "* term_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "doc_lengths = np.asarray(X.sum(axis=1)).reshape(-1)\n",
    "term_frequency = np.asarray(X.sum(axis=0)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docwords = [doc.split(' ') for doc in docs]\n",
    "vocab = list(set(word for document in docwords for word in document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmeans_to_pyLDAvis import kmeans_to_prepared_data\n",
    "\n",
    "vis_data = kmeans_to_prepared_data(\n",
    "    X,\n",
    "    vocab[1:],\n",
    "    centers,\n",
    "    labels,\n",
    "    n_printed_words = 10,\n",
    "    radius = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.save_html(vis_data, 'kmeans_pyLDAvis.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Freq</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1260</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084599</td>\n",
       "      <td>Echocardiographic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930829</td>\n",
       "      <td>followed-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1447</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953266</td>\n",
       "      <td>Serum-antibody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549004</td>\n",
       "      <td>smear-positive,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>787</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121786</td>\n",
       "      <td>Size,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term  Topic      Freq               Term\n",
       "0  1260      1  0.084599  Echocardiographic\n",
       "1   514      1  0.930829        followed-up\n",
       "2  1447      1  0.953266     Serum-antibody\n",
       "3  1531      1  0.549004    smear-positive,\n",
       "4   787      1  0.121786              Size,"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_data.token_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "#### 1. HBar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "hbar_json = {}\n",
    "hbar_json['labels'] = vis_data.topic_info.Category.unique().tolist()\n",
    "hbar_json['max_width'] = vis_data.topic_info[vis_data.topic_info.Category != 'Default'][['Total']].max()[0]\n",
    "for l in vis_data.topic_info.Category.unique().tolist():\n",
    "    tmp_df = vis_data.topic_info[vis_data.topic_info.Category == l].sort_values(['Category', 'Freq'], ascending=[True, False]).groupby('Category').head()\n",
    "    sub_json = {}\n",
    "\n",
    "    hbar_json[l] = list(tmp_df[['Term', 'Freq', 'Total']].sort_values('Freq', ascending=False).reset_index().to_dict('index').values())\n",
    "    \n",
    "f = open('./km/hbar_data.json', 'w')\n",
    "f.write(json.dumps(hbar_json, indent=4))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Scatter Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracelee/.pyenv/versions/for_jupyter/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>topic</th>\n",
       "      <th>plot_x</th>\n",
       "      <th>plot_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hazard Ratio  (and 95% Confidence Intervals)  in Univariate and Multivariate Analysis of Predictors of Major Cardiac Events  (Cardiac Death or Worsening of Heart Failure Leading to Heart Transplantation)</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.588774</td>\n",
       "      <td>15.092761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Left Ventricular and Right Ventricular Ejection Fractions, Left Ventricular and Right Ventricular Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations for Both Ventricles in 30 Cases of Left Sided WPW legend</td>\n",
       "      <td>2</td>\n",
       "      <td>-26.751963</td>\n",
       "      <td>-1.296253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Partial Regression Coefficients  (All Subjects, n = 262)  for Forward Stepwise Linear Regression for Dependent Variables Augmentation Pressure and Augmentation Index    legend</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.737872</td>\n",
       "      <td>5.312836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Left Ventricular  (LVEF)  and Right Ventricular  (RVEF)  Ejection Fractions, Left Ventricular  (LVMP)  and Right Ventricular  (RVMP)  Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations  (LVPSD and RVPSD)  for Both Ventricles in 14 Cases of Right Sided WPW legend</td>\n",
       "      <td>2</td>\n",
       "      <td>-26.751284</td>\n",
       "      <td>-1.296099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Predictors of Mortality by Multivariable Analysis: Variables Are Shown in the Order They Entered a Stepwise Cox Regression Model</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.516112</td>\n",
       "      <td>9.251663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                       document  \\\n",
       "0                                                                                                   Hazard Ratio  (and 95% Confidence Intervals)  in Univariate and Multivariate Analysis of Predictors of Major Cardiac Events  (Cardiac Death or Worsening of Heart Failure Leading to Heart Transplantation)   \n",
       "1                                                           Left Ventricular and Right Ventricular Ejection Fractions, Left Ventricular and Right Ventricular Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations for Both Ventricles in 30 Cases of Left Sided WPW legend   \n",
       "2                                                                                                                               Partial Regression Coefficients  (All Subjects, n = 262)  for Forward Stepwise Linear Regression for Dependent Variables Augmentation Pressure and Augmentation Index    legend   \n",
       "3  Left Ventricular  (LVEF)  and Right Ventricular  (RVEF)  Ejection Fractions, Left Ventricular  (LVMP)  and Right Ventricular  (RVMP)  Mean Phases, Left-to-Right Mean Phase Difference  (L-RMP)  and Phase Standard Deviations  (LVPSD and RVPSD)  for Both Ventricles in 14 Cases of Right Sided WPW legend   \n",
       "4                                                                                                                                                                              Predictors of Mortality by Multivariable Analysis: Variables Are Shown in the Order They Entered a Stepwise Cox Regression Model   \n",
       "\n",
       "   topic     plot_x     plot_y  \n",
       "0      7  -5.588774  15.092761  \n",
       "1      2 -26.751963  -1.296253  \n",
       "2      1  -7.737872   5.312836  \n",
       "3      2 -26.751284  -1.296099  \n",
       "4      0  -5.516112   9.251663  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result = documents[['index', 'Origin_Text']]\n",
    "doc_result.columns = ['id', 'document']\n",
    "doc_result['topic'] = kmeans_model.labels_\n",
    "doc_result = pd.merge(doc_result, pd.DataFrame(tsne_result, columns=['plot_x', 'plot_y']), left_index=True, right_index=True)\n",
    "\n",
    "doc_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_json = list(doc_result[['id', 'plot_x', 'plot_y', 'topic']].to_dict('index').values())\n",
    "\n",
    "f = open('./km/scatter_data.json', 'w')\n",
    "f.write(json.dumps(scatter_json, indent=4))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "doc_result['topic_word'] = processed_docs\n",
    "doc_result['words_count'] = doc_result.words.apply(lambda x : len(x))\n",
    "\n",
    "topic_words = {}\n",
    "for i in doc_result.topic.unique():\n",
    "    topic_words[i] = sorted({k: '%.2f' % (dict(collections.Counter(np.sum(doc_result[doc_result.topic == i].topic_word.values)))[k] / doc_result[doc_result.topic == i].words_count.sum() * 100) \\\n",
    "    for k in dict(collections.Counter(np.sum(doc_result[doc_result.topic == i].topic_word.values)))}.items(), key=lambda kv: kv[1], reverse=True)[:10]\n",
    "    \n",
    "doc_result.topic_word = doc_result.apply(lambda x: topic_words[x.topic], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result.to_csv('km.tsv', sep='\\t', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[(year, 3.19), (patient, 3.06), (risk, 2.64), (mortal, 2.36), (cancer, 2.08), (relat, 1.94), (specif, 1.81), (number, 1.81), (score, 1.81), (ratio, 1.81)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[(death, 7.22), (year, 6.67), (rat, 5.56), (ventricular, 4.44), (standardis, 3.89), (leav, 3.89), (right, 3.89), (caus, 3.89), (health, 3.33), (combin, 3.33)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[(patient, 2.58), (risk, 1.50), (model, 1.29), (death, 1.29), (analysi, 1.20), (regress, 1.20), (hazard, 1.12), (accord, 1.07), (score, 1.03), (coronari, 1.03)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>[(seri, 6.67), (physic, 6.67), (origin, 6.67), (imag, 6.67), (activ, 6.67), (compress, 6.67), (effect, 6.67), (intervent, 6.67), (stroke, 5.56), (legend, 4.44)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>[(grade, 6.22), (patient, 5.78), (popul, 5.11), (emerg, 4.89), (group, 4.67), (safeti, 4.67), (relat, 3.56), (studi, 2.89), (occur, 2.89), (drug, 2.67)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6</td>\n",
       "      <td>[(patient, 9.41), (coronari, 6.47), (year, 5.29), (myocardi, 4.12), (infarct, 4.12), (surviv, 3.53), (acut, 3.53), (random, 3.53), (hospit, 2.94), (failur, 2.94)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>4</td>\n",
       "      <td>[(legend, 7.50), (effect, 7.50), (cardiac, 2.50), (renin, 2.50), (respons, 2.50), (administ, 2.50), (interv, 2.50), (plasma, 2.50), (rate, 2.50), (myocardi, 2.50)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>5</td>\n",
       "      <td>[(chest, 5.00), (arteri, 5.00), (ctca, 5.00), (pain, 5.00), (index, 5.00), (myocardi, 5.00), (hospit, 5.00), (patient, 5.00), (accuraci, 5.00), (influenc, 5.00)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic  \\\n",
       "0        0   \n",
       "1        2   \n",
       "2        3   \n",
       "8        7   \n",
       "101      1   \n",
       "128      6   \n",
       "154      4   \n",
       "325      5   \n",
       "\n",
       "                                                                                                                                                              topic_word  \n",
       "0             [(year, 3.19), (patient, 3.06), (risk, 2.64), (mortal, 2.36), (cancer, 2.08), (relat, 1.94), (specif, 1.81), (number, 1.81), (score, 1.81), (ratio, 1.81)]  \n",
       "1         [(death, 7.22), (year, 6.67), (rat, 5.56), (ventricular, 4.44), (standardis, 3.89), (leav, 3.89), (right, 3.89), (caus, 3.89), (health, 3.33), (combin, 3.33)]  \n",
       "2       [(patient, 2.58), (risk, 1.50), (model, 1.29), (death, 1.29), (analysi, 1.20), (regress, 1.20), (hazard, 1.12), (accord, 1.07), (score, 1.03), (coronari, 1.03)]  \n",
       "8       [(seri, 6.67), (physic, 6.67), (origin, 6.67), (imag, 6.67), (activ, 6.67), (compress, 6.67), (effect, 6.67), (intervent, 6.67), (stroke, 5.56), (legend, 4.44)]  \n",
       "101             [(grade, 6.22), (patient, 5.78), (popul, 5.11), (emerg, 4.89), (group, 4.67), (safeti, 4.67), (relat, 3.56), (studi, 2.89), (occur, 2.89), (drug, 2.67)]  \n",
       "128   [(patient, 9.41), (coronari, 6.47), (year, 5.29), (myocardi, 4.12), (infarct, 4.12), (surviv, 3.53), (acut, 3.53), (random, 3.53), (hospit, 2.94), (failur, 2.94)]  \n",
       "154  [(legend, 7.50), (effect, 7.50), (cardiac, 2.50), (renin, 2.50), (respons, 2.50), (administ, 2.50), (interv, 2.50), (plasma, 2.50), (rate, 2.50), (myocardi, 2.50)]  \n",
       "325    [(chest, 5.00), (arteri, 5.00), (ctca, 5.00), (pain, 5.00), (index, 5.00), (myocardi, 5.00), (hospit, 5.00), (patient, 5.00), (accuraci, 5.00), (influenc, 5.00)]  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result.groupby('topic').head(1)[['topic', 'topic_word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 5, 21, 37, 51, 52, 54, 55, 59, 63, 64, 69, 73, 77, 81, 83, 85, 87, 91, 94, 96, 98, 99, 151, 169, 176, 178, 182, 200, 201, 204, 206, 208, 209, 210, 212, 213, 215, 216, 220, 221, 223, 225, 230, 231, 232, 241, 255, 267, 271, 279, 280, 282, 296, 314, 318, 322, 326, 337, 345, 349, 351, 352, 355, 356, 357, 358, 360, 361, 374, 376, 383]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 3, 56, 57, 202, 207, 211, 222, 227, 229, 237, 238, 245, 247, 272, 278, 304, 327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 84, 86, 88, 89, 90, 92, 93, 95, 97, 114, 115, 150, 152, 153, 157, 159, 160, 162, 163, 164, 165, 168, 170, 171, 172, 173, 174, 175, 177, 179, 185, 186, 187, 188, 189, 190, 191, 192, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[154, 155, 156, 161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[325, 342]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[128, 140, 158, 166, 167, 180, 181, 183, 184, 197, 203, 205, 236, 307, 310, 331, 375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[8, 50, 100, 261, 291, 311, 312, 321, 373]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                  id\n",
       "topic                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "0                                                                                                    [0, 5, 21, 37, 51, 52, 54, 55, 59, 63, 64, 69, 73, 77, 81, 83, 85, 87, 91, 94, 96, 98, 99, 151, 169, 176, 178, 182, 200, 201, 204, 206, 208, 209, 210, 212, 213, 215, 216, 220, 221, 223, 225, 230, 231, 232, 241, 255, 267, 271, 279, 280, 282, 296, 314, 318, 322, 326, 337, 345, 349, 351, 352, 355, 356, 357, 358, 360, 361, 374, 376, 383]\n",
       "1                                                                                                                                                                                                                  [101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
       "2                                                                                                                                                                                                                                                                                                                                                               [1, 3, 56, 57, 202, 207, 211, 222, 227, 229, 237, 238, 245, 247, 272, 278, 304, 327]\n",
       "3      [2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 84, 86, 88, 89, 90, 92, 93, 95, 97, 114, 115, 150, 152, 153, 157, 159, 160, 162, 163, 164, 165, 168, 170, 171, 172, 173, 174, 175, 177, 179, 185, 186, 187, 188, 189, 190, 191, 192, ...]\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                               [154, 155, 156, 161]\n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                         [325, 342]\n",
       "6                                                                                                                                                                                                                                                                                                                                                              [128, 140, 158, 166, 167, 180, 181, 183, 184, 197, 203, 205, 236, 307, 310, 331, 375]\n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                         [8, 50, 100, 261, 291, 311, 312, 321, 373]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result.groupby('topic').agg({'id': 'unique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
