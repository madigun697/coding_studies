{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://potatoggg.tistory.com/92\n",
    "* https://github.com/mutux/suffix-tries/blob/master/suffixtrie.py\n",
    "* http://www.cs.jhu.edu/~langmea/resources/lecture_notes/tries_and_suffix_tries.pdf\n",
    "* https://github.com/vancanhuit/simple-data-compression\n",
    "* https://github.com/etcwilde/lz_compression\n",
    "* http://faculty.kfupm.edu.sa/ICS/jauhar/ics202/Unit31_LZ78.ppt (얘가 제일 잘 정리)\n",
    "* https://www.cs.helsinki.fi/u/puglisi/dct2015/slides7.pdf (Trie가 있어...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic LZ78 (1555051, 1271185, 81.75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZ78_dict:\n",
    "    \n",
    "    def readfile(self, filename):\n",
    "        try:\n",
    "            f = open(filename, 'r')\n",
    "            data = f.readlines()\n",
    "            f.close()\n",
    "        except UnicodeDecodeError:\n",
    "            # 입력 스트림과 출력 스트림을 연다\n",
    "            input = open(filename, \"rt\", encoding=\"utf-16\")\n",
    "            data = ''\n",
    "\n",
    "            # 유니코드 데이터 조각들을 스트리밍한다\n",
    "            with input:\n",
    "                while True:\n",
    "                    # 데이터 조각을 읽고\n",
    "                    chunk = input.read(4096)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    # 수직 탭을 삭제한다\n",
    "                    chunk = chunk.replace(\"\\u000B\", \"\")\n",
    "                    # 데이터 조각을 쓴다\n",
    "                    data += chunk\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def compress(self, origin_file, compressed_file):\n",
    "        import struct \n",
    "        data = ''.join(self.readfile(origin_file))\n",
    "        encoded_data = self.encoding(data)\n",
    "        \n",
    "        binfile = open(compressed_file, 'wb') \n",
    "        for idx, ch in encoded_data:\n",
    "                \n",
    "            data = struct.pack('Ic', idx, ch.encode()) \n",
    "            binfile.write(data) \n",
    "        binfile.close()\n",
    "        \n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        import struct \n",
    "        binfile = open(compressed_file, 'rb')\n",
    "        intsize = struct.calcsize('Ic')\n",
    "        encoded_data = []\n",
    "\n",
    "        while True:\n",
    "            binary = binfile.read(intsize)\n",
    "            if binary == b'': \n",
    "                break \n",
    "            encoded_data.append(struct.unpack('Ic', binary))\n",
    "            \n",
    "        encoded_data = [(d[0], d[1].decode()) for d in encoded_data]\n",
    "        \n",
    "        decoded_data = self.decoding(encoded_data)\n",
    "        \n",
    "        f = open(decompressed_file, 'w')\n",
    "        f.write(decoded_data)\n",
    "        f.close()\n",
    "        \n",
    "    def encoding(self, data):\n",
    "        import collections\n",
    "        encode_dict = collections.OrderedDict()\n",
    "        out = []\n",
    "        out2 = []\n",
    "        key = ''\n",
    "        \n",
    "        for i, c in enumerate(data):\n",
    "            key += c\n",
    "            if key not in encode_dict:\n",
    "                out.append((encode_dict[key[:-1]] if len(key) > 1 else 0, c))\n",
    "                encode_dict[key] = len(encode_dict)+1\n",
    "                key = ''\n",
    "                \n",
    "        if key != '': out.append((encode_dict[key], ''))\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def decoding(self, data):\n",
    "        d = []\n",
    "        p = ''\n",
    "\n",
    "        for (w, c) in data: d.append(c if w == 0 else d[w-1] + c)\n",
    "\n",
    "        return ''.join(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check encoding/decoding logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78 = LZ78_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'i love computer science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love computer science'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = lz78.encoding(text)\n",
    "decoded_text = lz78.decoding(encoded_text)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABBCBCABABCAABCAAB [(0, 'A'), (0, 'B'), (2, 'C'), (3, 'A'), (2, 'A'), (4, 'A'), (6, 'B')] ABBCBCABABCAABCAAB True\n",
      "--------\n",
      "BABAABRRRA [(0, 'B'), (0, 'A'), (1, 'A'), (2, 'B'), (0, 'R'), (5, 'R'), (2, '')] BABAABRRRA True\n",
      "--------\n",
      "AAAAAAAAA [(0, 'A'), (1, 'A'), (2, 'A'), (3, '')] AAAAAAAAA True\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "data = ['ABBCBCABABCAABCAAB', 'BABAABRRRA', 'AAAAAAAAA']\n",
    "\n",
    "for origin_text in data:\n",
    "    lz78_ = LZ78_dict()\n",
    "    encoded_text = lz78_.encoding(origin_text)\n",
    "    decoded_text = lz78_.decoding(encoded_text)\n",
    "    print(origin_text, encoded_text, decoded_text, origin_text == decoded_text)\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test data compression and Calculate compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78 = LZ78_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.compress('infile.txt', 'compress.lz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.decompress('compress.lz', 'restore.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: infile.txt, \n",
      "Origin file size: 1,555,051Byte, \n",
      "Compressed size: 1,271,185Byte, \n",
      "Compression ratio: 81.745550%\n"
     ]
    }
   ],
   "source": [
    "print('File name: infile.txt, \\nOrigin file size: %sByte, \\nCompressed size: %sByte, \\nCompression ratio: %f%%' % \n",
    "('{:,}'.format(os.path.getsize('./infile.txt')), '{:,}'.format(os.path.getsize('./compress.lz')), \n",
    " os.path.getsize('./compress.lz')/os.path.getsize('./infile.txt')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 4byte LZ78 (1555051, 1016948, 65.4%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZ78_4byte:\n",
    "    \n",
    "    def readfile(self, filename):\n",
    "        try:\n",
    "            f = open(filename, 'r')\n",
    "            data = f.readlines()\n",
    "            f.close()\n",
    "        except UnicodeDecodeError:\n",
    "            # 입력 스트림과 출력 스트림을 연다\n",
    "            input = open(filename, \"rt\", encoding=\"utf-16\")\n",
    "            data = ''\n",
    "\n",
    "            # 유니코드 데이터 조각들을 스트리밍한다\n",
    "            with input:\n",
    "                while True:\n",
    "                    # 데이터 조각을 읽고\n",
    "                    chunk = input.read(4096)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    # 수직 탭을 삭제한다\n",
    "                    chunk = chunk.replace(\"\\u000B\", \"\")\n",
    "                    # 데이터 조각을 쓴다\n",
    "                    data += chunk\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def compress(self, origin_file, compressed_file):\n",
    "        import struct \n",
    "        \n",
    "        data = ''.join(self.readfile(origin_file))\n",
    "        encoded_data = self.encoding(data)\n",
    "        \n",
    "        maxidx = max([t[0] for t in encoded_data])\n",
    "        \n",
    "        if maxidx < 255:\n",
    "            bintype = 'Bc'\n",
    "        elif maxidx < 65535:\n",
    "            bintype = 'Hc'\n",
    "        elif maxidx < 16777215:\n",
    "            bintype = '4byte'\n",
    "        else:\n",
    "            bintype = 'Ic'\n",
    "        \n",
    "        binfile = open(compressed_file, 'wb')\n",
    "        binfile.write(struct.pack('c', bintype[:1].encode()))\n",
    "        for idx, ch in encoded_data:\n",
    "            if len(ch) == 0:\n",
    "                break\n",
    "            if bintype == '4byte':\n",
    "                data = struct.pack('Ic', idx, ch.encode())\n",
    "                binfile.write(b''.join([data[0:3], data[4:]])) \n",
    "            else:\n",
    "                data = struct.pack(bintype, idx, ch.encode())\n",
    "                binfile.write(data) \n",
    "        binfile.close()\n",
    "        \n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        import struct \n",
    "        binfile = open(compressed_file, 'rb')\n",
    "        a = binfile.read(1)\n",
    "        bintype = struct.unpack('c', a)[0].decode()\n",
    "        encoded_data = []\n",
    "\n",
    "        while True:\n",
    "            if bintype == '4':\n",
    "                binary = binfile.read(struct.calcsize('Ic') - 1)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack('Ic', b''.join([binary[0:3], b'\\x00', binary[3:]])))\n",
    "            else:\n",
    "                binary = binfile.read(struct.calcsize('%sc' % bintype))\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack('%sc' % bintype, binary))\n",
    "            \n",
    "        encoded_data = [(d[0], d[1].decode()) for d in encoded_data]\n",
    "        \n",
    "        decoded_data = self.decoding(encoded_data)\n",
    "        \n",
    "        f = open(decompressed_file, 'w')\n",
    "        f.write(decoded_data)\n",
    "        f.close()\n",
    "        \n",
    "    def encoding(self, data):\n",
    "        import collections\n",
    "        encode_dict = collections.OrderedDict()\n",
    "        out = []\n",
    "        out2 = []\n",
    "        key = ''\n",
    "        \n",
    "        for i, c in enumerate(data):\n",
    "            key += c\n",
    "            if key not in encode_dict:\n",
    "                out.append((encode_dict[key[:-1]] if len(key) > 1 else 0, c))\n",
    "                encode_dict[key] = len(encode_dict)+1\n",
    "                key = ''\n",
    "                \n",
    "        if key != '': out.append((encode_dict[key], ''))\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def decoding(self, data):\n",
    "        d = []\n",
    "        p = ''\n",
    "\n",
    "        for (w, c) in data: d.append(c if w == 0 else d[w-1] + c)\n",
    "\n",
    "        return ''.join(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test data compression and Calculate compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78 = LZ78_4byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.compress('infile.txt', 'compress.lz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.decompress('compress.lz', 'restore.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: infile.txt, \n",
      "Origin file size: 1,555,051Byte, \n",
      "Compressed size: 1,016,949Byte, \n",
      "Compression ratio: 65.396505%\n"
     ]
    }
   ],
   "source": [
    "print('File name: infile.txt, \\nOrigin file size: %sByte, \\nCompressed size: %sByte, \\nCompression ratio: %f%%' % \n",
    "('{:,}'.format(os.path.getsize('./infile.txt')), '{:,}'.format(os.path.getsize('./compress.lz')), \n",
    " os.path.getsize('./compress.lz')/os.path.getsize('./infile.txt')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test each type of byte\n",
    "    * infile2.txt: 2byte\n",
    "    * infile3.txt: 3byte\n",
    "    * infile.txt: 4byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2byte\n",
      "File name: infile2.txt, \n",
      "Origin file size: 518Byte, \n",
      "Compressed size: 445Byte, \n",
      "Compression ratio: 85.907336%\n",
      "\n",
      "Test 3byte\n",
      "File name: infile3.txt, \n",
      "Origin file size: 2,452Byte, \n",
      "Compressed size: 2,434Byte, \n",
      "Compression ratio: 99.265905%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 4):\n",
    "    lz78 = LZ78_4byte()\n",
    "    lz78.compress('infile%d.txt' % i, 'compress%d.lz' % i)\n",
    "    lz78.decompress('compress%d.lz' % i, 'restore%d.txt' % i)\n",
    "    print('Test %dbyte' % i)\n",
    "    print('File name: infile%d.txt, \\nOrigin file size: %sByte, \\nCompressed size: %sByte, \\nCompression ratio: %f%%\\n' % \n",
    "          (i, '{:,}'.format(os.path.getsize('./infile%d.txt' % i)), '{:,}'.format(os.path.getsize('./compress%d.lz' % i)), \n",
    "           os.path.getsize('./compress%d.lz' % i)/os.path.getsize('./infile%d.txt' % i)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Switch LZ78 (1555051, 951156, 61.17%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZ78_switch:\n",
    "    \n",
    "    def readfile(self, filename):\n",
    "        try:\n",
    "            f = open(filename, 'r')\n",
    "            data = f.readlines()\n",
    "            f.close()\n",
    "        except UnicodeDecodeError:\n",
    "            # 입력 스트림과 출력 스트림을 연다\n",
    "            input = open(filename, \"rt\", encoding=\"utf-16\")\n",
    "            data = ''\n",
    "\n",
    "            # 유니코드 데이터 조각들을 스트리밍한다\n",
    "            with input:\n",
    "                while True:\n",
    "                    # 데이터 조각을 읽고\n",
    "                    chunk = input.read(4096)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    # 수직 탭을 삭제한다\n",
    "                    chunk = chunk.replace(\"\\u000B\", \"\")\n",
    "                    # 데이터 조각을 쓴다\n",
    "                    data += chunk\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def compress(self, origin_file, compressed_file):\n",
    "        import struct \n",
    "        \n",
    "        data = ''.join(self.readfile(origin_file))\n",
    "        encoded_data = self.encoding(data)\n",
    "                \n",
    "        binfile = open(compressed_file, 'wb')\n",
    "        for i, (idx, ch) in enumerate(encoded_data):\n",
    "            if len(ch) == 0:\n",
    "                break\n",
    "                                        \n",
    "            if i <= 255:\n",
    "                binsize = 2\n",
    "                data = struct.pack('Bc', idx, ch.encode())\n",
    "                binfile.write(data) \n",
    "            elif i <= 65535:\n",
    "                binsize = 3\n",
    "                data = struct.pack('Hc', idx, ch.encode())\n",
    "                binfile.write(data) \n",
    "            elif i <= 16777215:\n",
    "                binsize = 4\n",
    "                data = struct.pack('Ic', idx, ch.encode())\n",
    "                binfile.write(b''.join([data[0:3], data[4:]])) \n",
    "            else:\n",
    "                binsize = 5\n",
    "                data = struct.pack('Ic', idx, ch.encode())\n",
    "                binfile.write(data)            \n",
    "            \n",
    "        binfile.close()\n",
    "        \n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        import struct \n",
    "        binfile = open(compressed_file, 'rb')\n",
    "        bintype = {2: 'Bc', 3: 'Hc', 4: 'Ic', 5: 'Ic'}\n",
    "               \n",
    "        encoded_data = []\n",
    "        seq = 0\n",
    "        \n",
    "        while True:\n",
    "            if seq <= 255:\n",
    "                binsize = 2\n",
    "                binary = binfile.read(binsize)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack(bintype[binsize], binary))\n",
    "            elif seq <= 65535:\n",
    "                binsize = 3\n",
    "                binary = binfile.read(binsize)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack(bintype[binsize], binary))\n",
    "            elif seq <= 16777215:\n",
    "                binsize = 4\n",
    "                binary = binfile.read(binsize)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack(bintype[binsize], b''.join([binary[0:3], b'\\x00', binary[3:]])))\n",
    "            else:\n",
    "                binsize = 5\n",
    "                binary = binfile.read(binsize)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack(bintype[binsize], binary))\n",
    "                \n",
    "            seq += 1\n",
    "        \n",
    "        encoded_data = [(d[0], d[1].decode()) for d in encoded_data]\n",
    "        decoded_data = self.decoding(encoded_data)\n",
    "        \n",
    "        f = open(decompressed_file, 'w')\n",
    "        f.write(decoded_data)\n",
    "        f.close()\n",
    "        \n",
    "    def encoding(self, data):\n",
    "        import collections\n",
    "        encode_dict = collections.OrderedDict()\n",
    "        out = []\n",
    "        out2 = []\n",
    "        key = ''\n",
    "        \n",
    "        for i, c in enumerate(data):\n",
    "            key += c\n",
    "            if key not in encode_dict:\n",
    "                out.append((encode_dict[key[:-1]] if len(key) > 1 else 0, c))\n",
    "                encode_dict[key] = len(encode_dict)+1\n",
    "                key = ''\n",
    "                \n",
    "        if key != '': out.append((encode_dict[key], ''))\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def decoding(self, data):\n",
    "        d = []\n",
    "        p = ''\n",
    "\n",
    "        for (w, c) in data: d.append(c if w == 0 else d[w-1] + c)\n",
    "\n",
    "        return ''.join(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test data compression and Calculate compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78 = LZ78_switch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.compress('infile.txt', 'compress.lz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.decompress('compress.lz', 'restore.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: infile.txt, \n",
      "Origin file size: 1,555,051Byte, \n",
      "Compressed size: 951,156Byte, \n",
      "Compression ratio: 61.165582%\n"
     ]
    }
   ],
   "source": [
    "print('File name: infile.txt, \\nOrigin file size: %sByte, \\nCompressed size: %sByte, \\nCompression ratio: %f%%' % \n",
    "('{:,}'.format(os.path.getsize('./infile.txt')), '{:,}'.format(os.path.getsize('./compress.lz')), \n",
    " os.path.getsize('./compress.lz')/os.path.getsize('./infile.txt')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test each type of byte\n",
    "    * infile2.txt: 2byte\n",
    "    * infile3.txt: 3byte\n",
    "    * infile.txt: 4byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2byte\n",
      "File name: infile2.txt, \n",
      "Origin file size: 518Byte, \n",
      "Compressed size: 444Byte, \n",
      "Compression ratio: 85.714286%\n",
      "\n",
      "Test 3byte\n",
      "File name: infile3.txt, \n",
      "Origin file size: 2,452Byte, \n",
      "Compressed size: 2,177Byte, \n",
      "Compression ratio: 88.784666%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 4):\n",
    "    lz78 = LZ78_switch()\n",
    "    lz78.compress('infile%d.txt' % i, 'compress%d.lz' % i)\n",
    "    lz78.decompress('compress%d.lz' % i, 'restore%d.txt' % i)\n",
    "    print('Test %dbyte' % i)\n",
    "    print('File name: infile%d.txt, \\nOrigin file size: %sByte, \\nCompressed size: %sByte, \\nCompression ratio: %f%%\\n' % \n",
    "          (i, '{:,}'.format(os.path.getsize('./infile%d.txt' % i)), '{:,}'.format(os.path.getsize('./compress%d.lz' % i)), \n",
    "           os.path.getsize('./compress%d.lz' % i)/os.path.getsize('./infile%d.txt' % i)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unicode File Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: infile_unicode.txt, \n",
      "Origin file size: 1,038Byte, \n",
      "Compressed size: 444Byte, \n",
      "Compression ratio: 42.774566%\n"
     ]
    }
   ],
   "source": [
    "lz78 = LZ78_switch()\n",
    "lz78.compress('infile_unicode.txt', 'compress_unicode.lz')\n",
    "lz78.decompress('compress_unicode.lz', 'restore_unicode.txt')\n",
    "\n",
    "print('File name: infile_unicode.txt, \\nOrigin file size: %sByte, \\nCompressed size: %sByte, \\nCompression ratio: %f%%' % \n",
    "('{:,}'.format(os.path.getsize('./infile_unicode.txt')), '{:,}'.format(os.path.getsize('./compress_unicode.lz')), \n",
    " os.path.getsize('./compress_unicode.lz')/os.path.getsize('./infile_unicode.txt')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Switch LZ78 with Trie (1555051, 951156, 61.17%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZ78_trie:\n",
    "    \n",
    "    def readfile(self, filename):\n",
    "        try:\n",
    "            f = open(filename, 'r')\n",
    "            data = f.readlines()\n",
    "            f.close()\n",
    "        except UnicodeDecodeError:\n",
    "            # 입력 스트림과 출력 스트림을 연다\n",
    "            input = open(filename, \"rt\", encoding=\"utf-16\")\n",
    "            data = ''\n",
    "\n",
    "            # 유니코드 데이터 조각들을 스트리밍한다\n",
    "            with input:\n",
    "                while True:\n",
    "                    # 데이터 조각을 읽고\n",
    "                    chunk = input.read(4096)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    # 수직 탭을 삭제한다\n",
    "                    chunk = chunk.replace(\"\\u000B\", \"\")\n",
    "                    # 데이터 조각을 쓴다\n",
    "                    data += chunk\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def compress(self, origin_file, compressed_file):\n",
    "        import struct \n",
    "        \n",
    "        data = ''.join(self.readfile(origin_file))\n",
    "        encoded_data = self.encoding(data)\n",
    "                \n",
    "        binfile = open(compressed_file, 'wb')\n",
    "        for i, (idx, ch) in enumerate(encoded_data):\n",
    "                        \n",
    "            if i <= 255:\n",
    "#                 binsize = 2\n",
    "                data = struct.pack('Bc', idx, ch.encode() if len(ch) > 0 else b'\\x00')\n",
    "                binfile.write(data) \n",
    "            elif i <= 65535:\n",
    "#                 binsize = 3\n",
    "                data = struct.pack('Hc', idx, ch.encode() if len(ch) > 0 else b'\\x00')\n",
    "                binfile.write(data) \n",
    "            elif i <= 16777215:\n",
    "#                 binsize = 4\n",
    "                data = struct.pack('Ic', idx, ch.encode() if len(ch) > 0 else b'\\x00')\n",
    "                binfile.write(b''.join([data[0:3], data[4:]])) \n",
    "            else:\n",
    "#                 binsize = 5\n",
    "                data = struct.pack('Ic', idx, ch.encode() if len(ch) > 0 else b'\\x00')\n",
    "                binfile.write(data)            \n",
    "            \n",
    "        binfile.close()\n",
    "        \n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        import struct \n",
    "        binfile = open(compressed_file, 'rb')\n",
    "        bintype = {2: 'Bc', 3: 'Hc', 4: 'Ic', 5: 'Ic'}\n",
    "               \n",
    "        encoded_data = []\n",
    "        seq = 0\n",
    "        \n",
    "        while True:\n",
    "            if seq <= 255:\n",
    "                binsize = 2\n",
    "                binary = binfile.read(binsize)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack(bintype[binsize], binary))\n",
    "            elif seq <= 65535:\n",
    "                binsize = 3\n",
    "                binary = binfile.read(binsize)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack(bintype[binsize], binary))\n",
    "            elif seq <= 16777215:\n",
    "                binsize = 4\n",
    "                binary = binfile.read(binsize)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack(bintype[binsize], b''.join([binary[0:3], b'\\x00', binary[3:]])))\n",
    "            else:\n",
    "                binsize = 5\n",
    "                binary = binfile.read(binsize)\n",
    "                if binary == b'': break \n",
    "                encoded_data.append(struct.unpack(bintype[binsize], binary))\n",
    "                \n",
    "            seq += 1\n",
    "        \n",
    "        if encoded_data[-1][1] == b'\\x00':\n",
    "            encoded_data[-1] = (encoded_data[-1][0], b'')\n",
    "            \n",
    "        encoded_data = [(d[0], d[1].decode()) for d in encoded_data]\n",
    "        decoded_data = self.decoding(encoded_data)\n",
    "        \n",
    "        f = open(decompressed_file, 'w')\n",
    "        f.write(decoded_data)\n",
    "        f.close()\n",
    "        \n",
    "    def getEmptyTrie(self, data):\n",
    "        available_characters = [i for i in range(ord('a'), ord('z')+1)] + \\\n",
    "            [i for i in range(ord('A'), ord('Z')+1)] + \\\n",
    "            [i for i in range(ord('0'), ord('9')+1)] + \\\n",
    "            [ord('!'), ord('?'), ord(' '), ord(','), ord('.'), ord(':'), ord(';'), ord('\\n')]\n",
    "        available_characters_dict = {}\n",
    "        for i, c in enumerate(available_characters): available_characters_dict[chr(c)] = i\n",
    "            \n",
    "        return [[-1]*70 for _ in range(len(data))], available_characters_dict\n",
    "        \n",
    "    def encoding(self, data):\n",
    "        out = []\n",
    "        trie, available_characters_dict = self.getEmptyTrie(data)\n",
    "        presentState = 0\n",
    "        state = 1\n",
    "        \n",
    "        key = ''\n",
    "        for c in data:\n",
    "            ch = available_characters_dict[c]\n",
    "            if trie[presentState][ch] == -1:\n",
    "                trie[presentState][ch] = state\n",
    "                out.append((presentState, c))\n",
    "                presentState = 0\n",
    "                state += 1\n",
    "            else:\n",
    "                presentState = trie[presentState][ch]\n",
    "        \n",
    "        if presentState > 0: out.append((presentState, ''))\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def decoding(self, data):\n",
    "        d = []\n",
    "\n",
    "        for (w, c) in data: d.append(c if w == 0 else d[w-1] + c)\n",
    "\n",
    "        return ''.join(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test data compression and Calculate compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78 = LZ78_trie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.compress('infile.txt', 'compress.lz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.decompress('compress.lz', 'restore.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: infile.txt, \n",
      "Origin file size: 1,555,051Byte, \n",
      "Compressed size: 951,156Byte, \n",
      "Compression ratio: 61.165582%\n"
     ]
    }
   ],
   "source": [
    "print('File name: infile.txt, \\nOrigin file size: %sByte, \\nCompressed size: %sByte, \\nCompression ratio: %f%%' % \n",
    "('{:,}'.format(os.path.getsize('./infile.txt')), '{:,}'.format(os.path.getsize('./compress.lz')), \n",
    " os.path.getsize('./compress.lz')/os.path.getsize('./infile.txt')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78 = LZ78_trie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.compress('aladdin.txt', 'compress_aladdin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz78.decompress('compress_aladdin', 'aladdin_restore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
